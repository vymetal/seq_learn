#!/usr/bin/python
from seqdata import getset
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier
from sklearn.pipeline import make_pipeline
import matplotlib.pylab as plt
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.decomposition import PCA,NMF
from sklearn.manifold import TSNE,MDS
import umap
import umap.plot

X,y=getset(7)
X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1234567, shuffle=True)


#tf=umap.UMAP(metric='correlation')
#R=tf.fit_transform(X_train)
#umap.plot.points(tf,labels=y_train)
#plt.scatter(R[:,0],R[:,1],alpha=0.1,s=1)
#plt.show()
#exit()
#model=LogisticRegression() #solver="saga")
#model=SGDClassifier(random_state=1234567, class_weight = "balanced")
#model =SGDClassifier(alpha=0.001, class_weight='balanced', loss='log', random_state=1234567)

#params={"loss":["hinge","log","modified_huber","perceptron","huber","epsilon_insensitive"], "penalty":["l1","l2"]}
#search=GridSearchCV(model, params, verbose=100)
params={}
#params["alpha"]=[1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0]
#search=RandomizedSearchCV(model, params, verbose=100, random_state=1234567)
#search=GridSearchCV(model, params, verbose=100)

#search.fit(X_train, y_train)
#print (search.best_estimator_)
#print (search.best_score_)
#print (search.cv_results_)
########
#exit()
#trans=PCA(n_components=100)
trans=NMF(n_components=50)

pipeline=make_pipeline(trans,model)
pipeline.fit(X_train, y_train)
print (pipeline.score(X_train, y_train))
print (pipeline.score(X_test, y_test))

#model.fit(X_train, y_train)
#print (model.score(X_train, y_train))
#print (model.score(X_test, y_test))

y_pred=pipeline.predict(X_test)
plt.hist(y_test,bins=20)
plt.figure()
plt.hist(y_pred,bins=20)
plt.show()
